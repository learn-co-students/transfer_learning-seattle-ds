{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator,\\\n",
    "array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind transfer learning is simply to make use of some pre-trained model to make predictions, rather than building a new model from scratch.\n",
    "\n",
    "The plain fact is that several very powerful image-processing networks have already been built and perfected by scientists who have detailed knowledge about how all the layers of their models work. Moreover, many successful models have been trained on hundreds of thousands if not millions of images, and so they could be used for your images as well.\n",
    "\n",
    "In general, the target will of course be different from the original that was used in training the model in the first place. But the idea is that the model will be good at picking up on the *deep features* of images, and so we can use *most* of the pre-trained model, in order to extract those deep features, and then just stick on a couple extra layers at the end that are appropriate for the data we have.\n",
    "\n",
    "In what follows here we'll try building a network from scratch on some chest X-ray data. And then we'll see if we can get better accuracy by using [Imagenet](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/), a leading CNN for image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some X-rays of lungs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = './chest_xray/train/'\n",
    "test_f = './chest_xray/test/'\n",
    "val_f = './chest_xray/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras's ImageDataGenerator can convert images (we have JPEGs here) to tensors of visual information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_f, \n",
    "        target_size=(64, 64))\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_f, \n",
    "        target_size=(64, 64))\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_f, \n",
    "        target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator uses *data augmentation*, which means that it will take each image and transform it in various ways, ultimately using *only these transformations* as training data. [Here's](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/) a nice resource on keras's `ImageDataGenerator`.\n",
    "\n",
    "And [here](https://bair.berkeley.edu/blog/2019/06/07/data_aug/) is a page with more information about data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_log = model.fit(train_images,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the acc and val_acc scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with Transfer Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool comes from the [Visual Geometry Group](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_base = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(64, 64, 3)\n",
    "                )\n",
    "\n",
    "cnn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, sample_amount):\n",
    "    features = np.zeros(shape=(sample_amount, 2, 2, 512)) \n",
    "    labels = np.zeros(shape=(sample_amount))\n",
    "    generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        directory, target_size=(64, 64), \n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = cnn_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch \n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_amount:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_f, 5216) \n",
    "validation_features, validation_labels = extract_features(val_f, 16) \n",
    "test_features, test_labels = extract_features(test_f, 624)\n",
    "\n",
    "train_features = np.reshape(train_features, (5216, 2048))\n",
    "validation_features = np.reshape(validation_features, (16, 2048))\n",
    "test_features = np.reshape(test_features, (624, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=2048))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=10,\n",
    "                    validation_data=(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore\n",
    "What other networks are available inside keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use transfer learning with another pre-trained CNN on these data.\n",
    "# See if you can improve on our metrics!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
